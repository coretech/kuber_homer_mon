apiVersion: v1

kind: ConfigMap
metadata:
  name: telegraf-config
  namespace: telegraf2
data:
  telegraf.conf: |+
   [global_tags]

    # Configuration for telegraf agent
    [agent]
      ## Default data collection interval for all inputs
      interval = "10s"
      ## Rounds collection interval to 'interval'
      ## ie, if interval="10s" then always collect on :00, :10, :20, etc.
      round_interval = true

      ## Telegraf will send metrics to outputs in batches of at most
      ## metric_batch_size metrics.
      ## This controls the size of writes that Telegraf sends to output plugins.
      metric_batch_size = 1000

      ## For failed writes, telegraf will cache metric_buffer_limit metrics for each
      ## output, and will flush this buffer on a successful write. Oldest metrics
      ## are dropped first when this buffer fills.
      ## This buffer only fills when writes fail to output plugin(s).
      metric_buffer_limit = 10000

      ## Collection jitter is used to jitter the collection by a random amount.
      ## Each plugin will sleep for a random time within jitter before collecting.
      ## This can be used to avoid many plugins querying things like sysfs at the
      ## same time, which can have a measurable effect on the system.
      collection_jitter = "0s"

      ## Default flushing interval for all outputs. Maximum flush_interval will be
      ## flush_interval + flush_jitter
      flush_interval = "10s"
      ## Jitter the flush interval by a random amount. This is primarily to avoid
      ## large write spikes for users running a large number of telegraf instances.
      ## ie, a jitter of 5s and interval 10s means flushes will happen every 10-15s
      flush_jitter = "0s"

     precision = ""

      ## Logging configuration:
      ## Run telegraf with debug log messages.
      debug = true
      ## Run telegraf in quiet mode (error log messages only).
      quiet = false
      ## Specify the log file name. The empty string means to log to stderr.
      logfile = ""

      ## Override default hostname, if empty use os.Hostname()
      hostname = "telegraf-kuber"
      ## If set to true, do no set the "host" tag in the telegraf agent.
      omit_hostname = true


    ###############################################################################
    #                            OUTPUT PLUGINS                                   #
    ###############################################################################

      #    # Configuration for sending metrics to InfluxDB
      #    [[outputs.influxdb]]
      #      urls = ["http://10.233.48.203:8086"]
      #      #username = "admin"
      #      #password = "kraken"
      #      #      database = "health" # required
      #      database = "gatling" # required
      #      timeout = "5s"
      #      namepass = ["host_stats*"]
      #
    [[outputs.influxdb]]
      urls = ["http://10.233.48.203:8086"]
 
       ## The target database for metrics; will be created as needed.
      database = "http-error"
 
       ## HTTP Basic Auth
       #username = "admin"
       #password = "kraken"
 
      timeout = "5s"
     #  database = "fspbx_errors"
     # namepass = ["fspbx_errors_*","fspbx_http"]

  

    [[processors.starlark]]

     namepass = ["kafka_consumer"]
     source = '''
   load("json.star", "json")
   load("logging.star", "log")
   def apply(metric):
               #print(metric.fields.get("value"))
               j = json.decode(metric.fields.get("value")) # json
               metrics=[]
               for group in j:    #  array of jason elements  to become Metrics
                      new_metric = Metric("fspbx_http")
                      if  "hostname" in j:
                         new_metric.tags["server_hostname"] = str(j["hostname"])
                         new_metric.fields["request_time"] = int(j["request_time"])
                         new_metric.tags["status"] = str(j["status"])
                         metrics.append(new_metric)
               return metrics
    '''    
           
    [processors.starlark.constants]

    debug_mode = true


    [[inputs.kafka_consumer]]

       brokers = ["145.239.102.212:9092","51.195.69.231:9092","137.74.249.153:9092"]
       topics = ["fspbx_errors"]
       #       name_prefix = "fspbx_errors_"
       #client_id = "Telegraf_prod2"
       #consumer_group = "telegraf_metrics_consumers_2"
       data_format = "value"
       data_type = "string"

